{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install Wand","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install mlxtend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading helpful packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_learning_curves\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier as rf\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier as dt\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report, roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay, RocCurveDisplay\nfrom sklearn.model_selection import learning_curve\nfrom xgboost import XGBClassifier as xgb\nfrom xgboost import plot_tree\nfrom tabulate import tabulate\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading extraction data\ndf_1 = pd.read_excel(\"/kaggle/input/extraction-non-extraction/final_data_extraction.xlsx\", index_col = 'Case no.')\n#Loading non-extraction data\ndf_2 = pd.read_excel(\"/kaggle/input/extraction-non-extraction/final_data_non_extraction.xlsx\", index_col = 'Case no.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on dataframe containing extraction data : \")\ndf_1.info()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elll = df_1['E-line to lower lip'].tolist()\nfor i in range(len(elll)):\n    if isinstance(elll[i], str):\n        try:\n            elll[i] = float(elll[i])\n        except:\n            b = elll[i].split(\" \")\n            s = ''\n            for j in b:\n                s+=j\n            elll[i] = float(s)\ndf_1['E-line to lower lip'] = elll","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on dataframe containing extraction data after cleaning \\'E-line to lower lip\\' column : \")\ndf_1.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on dataframe containing non-extraction data : \")\ndf_2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1 = df_1.rename(columns={'β angle': 'beta angle', 'UI-NA in °': 'UI-NA in deg', 'LI-NB in °': 'LI-NB in deg', 'E-line to lower lip':'E-Line to lower lip'})\ndf_2 = df_2.rename(columns={'β angle': 'beta angle', 'UI-NA in °': 'UI-NA in deg', 'LI-NB in °': 'LI-NB in deg', 'Nasiomental angle':'Nasomental angle', 'E-line to lower lip':'E-Line to lower lip'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extraction\ndf_1['Category'] = 1 \n# Non-extraction\ndf_2['Category'] = 0 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging df_1 and df_2\ndf_merged = pd.concat([df_1, df_2], axis=0)\ndf_merged.sample(frac=1).reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on the merged dataframe : \")\ndf_merged.info()\nprint(\"Description of the merged dataframe : \")\ndf_merged.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing the rows where E-Line to lower lip is null \ndf_merged = df_merged[df_merged['E-Line to lower lip'].notna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on the merged dataframe : \")\ndf_merged.info()\nprint(\"Description of the merged dataframe : \")\ndf_merged.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"head(50) of df_merged dataframe : \")\ndf_merged.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = df_merged['Category']\nX = df_merged.drop(['Category'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into train and test datasets\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenating X_train and Y_train to get the correlation matrix\ntrain_data_corr = pd.concat([X_train, Y_train], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Font specifications for plotting and tabulation\nfont1 = {'family': 'serif',\n        'color':  'darkred',\n        'weight': 'bold',\n        'size': 18,\n        }\n\nfont2 = {'family': 'serif',\n        'color':  'darkolivegreen',\n        'weight': 'bold',\n        'size': 12,\n        }\n\n# font3 = {'family': 'serif',\n#         'color':  'whitesmoke',\n#         'weight': 'bold',\n#         }\n\n#font3 = fm.FontProperties(family=['serif'], weight='bold', color='red')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create correlation matrix\ncorr_matrix = train_data_corr.corr().abs()\nprint(\"Correlation matrix\")\n\n#Plotting the correlation heatmap\nfig, ax = plt.subplots(figsize=(12,12))\nax.tick_params(colors='darkblue')\nax.xaxis.set_ticks_position('top')\nax.xaxis.set_label_position('top')\nplt.title(\"Correlation Matrix\", fontdict = font1, y = -0.1)\nplt.xlabel('Features', fontdict = font2)\nplt.ylabel('Features', fontdict = font2) \nsns.heatmap(corr_matrix, annot=True, fmt='.2f', linewidths=1.0, xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns, ax=ax)\nplt.savefig(\"Correlation_matrix\", facecolor = \"white\", transparent=False)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find features with correlation greater than 0.5\ndrop_columns = [column for column in upper.columns if any(upper[column] > 0.5)]\ndrop_columns.extend(['Name', 'Bolton\\'s'])\n\n#Removing 'Category' from drop_columns since its already removed from X_train and X_test\nif 'Category' in drop_columns:\n    drop_columns.remove('Category')\n\nprint(\"Columns to be dropped : \")\nfor col in drop_columns:\n     print(col)\n\n# Drop features \nX_train.drop(drop_columns, axis=1, inplace=True)\nX_test.drop(drop_columns, axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on X_train dataframe : \")\nX_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Information on X_test dataframe : \")\nX_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification models used in this experiment : \")\nmodel_names = [\"DecisionTreeClassifier\", \"RandomForestClassifier\", \"XGBoostClassifier\"]\n\nfor m in model_names:\n    print(m)\n\nX_train = X_train.values\nX_test = X_test.values\n\n#Decision Tree\ndt_model = dt().fit(X_train, Y_train)\n\n#Random Forest\nrf_model = rf().fit(X_train, Y_train)\n\n#XGBoost\nxgb_model = xgb().fit(X_train, Y_train)\n\nmodels = [dt_model, rf_model, xgb_model]\n\nmax_f1 = -float('inf')\nbest_model = \"\"\ntabulation_data = []\nY_names = [\"\"]\n\nfor model in models:\n    y_1 = model.predict(X_test)\n    y_2 = Y_test\n    model_name = str(type(model))[1:-2].split(\" \")[1].split(\".\")[-1]\n    file_name_cm = \"CM_\" + model_name\n    file_name_roc = \"ROC_\" + model_name\n    print(\"\\nPrinting the metrics for the\",model_name,\"model :\")\n    conf_matrix = confusion_matrix(y_2, y_1)\n    \n    fig, ax = plt.subplots(figsize=(8,8))\n    ax.tick_params(colors='darkblue')\n    ax.xaxis.set_ticks_position('top')\n    ax.xaxis.set_label_position('top')\n    ax.set_yticklabels(ax.get_yticks(), rotation = 75)\n    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Non-extraction', 'Extraction'])\n    disp.plot(ax=ax, colorbar=False)\n    title_str = 'Confusion Matrix for ' + model_name\n    plt.title(title_str, fontdict = font1, y = -0.1)\n    plt.xlabel('Predicted Labels', fontdict = font2)\n    plt.ylabel('Actual Labels', fontdict = font2) \n    plt.savefig(file_name_cm, facecolor = \"white\", sa=False)\n    plt.show()\n    \n    fig, ax = plt.subplots(figsize=(8,8))\n    fpr, tpr, thresholds = roc_curve(y_2, y_1)\n    roc_auc = auc(fpr, tpr)\n    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=model_name)\n    display.plot(ax = ax, name = \"ROC curve for \" + model_name)\n    plt.title(\"ROC curve for \" + model_name, fontdict = font1, y = -0.15)\n    plt.savefig(file_name_roc, facecolor = \"white\", sa=False)\n    plt.show()\n\n    accuracy_sc = round(accuracy_score(y_2, y_1), ndigits = 3)\n    f1_sc = round(f1_score(y_2, y_1), ndigits = 3)\n    precision_sc = round(precision_score(y_2, y_1), ndigits = 3)\n    recall_sc = round(recall_score(y_2, y_1), ndigits = 3)\n    print(\"\\n\\nClassification report : \\n\")\n    print(classification_report(y_2, y_1, target_names=['Non-extraction', 'Extraction']))\n    print('Accuracy :', accuracy_sc)\n    f1 = f1_sc\n    if f1 > max_f1:\n        max_f1 = f1\n        best_model = {\"model\":model, \"model_name\":model_name}\n    print(\"F1 score :\", f1_sc)\n    print(\"Precision score :\", precision_sc)\n    print(\"Recall score :\", recall_sc)\n    print(\"ROC Area under Curve for \" + model_name + \" :\", round(roc_auc, ndigits = 3))\n    tabulation_data.append([model_name, accuracy_sc, precision_sc, recall_sc, f1_sc])\nprint(\"\\nBest model for the given data is :\", best_model[\"model_name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_curves(X_train, Y_train, X_test, Y_test, dt_model)\nplt.title(\"Learning curve of \"+model_names[0], fontdict = font1, y = -0.3)\nplt.savefig(\"Learning_curve_\"+model_names[0], sa=False, bbox_inches='tight')\nplt.show()\n\nplot_learning_curves(X_train, Y_train, X_test, Y_test, rf_model)\nplt.title(\"Learning curve of \"+model_names[1], fontdict = font1, y = -0.3)\nplt.savefig(\"Learning_curve_\"+model_names[1], sa=False, bbox_inches='tight')\nplt.show()\n\nplot_learning_curves(X_train, Y_train, X_test, Y_test, xgb_model)\nplt.title(\"Learning curve of \"+model_names[2], fontdict = font1, y = -0.3)\nplt.savefig(\"Learning_curve_\"+model_names[2], sa=False, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = X.columns.values\nclass_names = ['Non-extraction', 'Extraction']\n\nfig, ax = plt.subplots(figsize=(42,42))\nax.set_title(\"Visual represenation of decision tree\")\ntree.plot_tree(dt_model, feature_names = feature_names, class_names = class_names, filled=True)\nplt.savefig(\"DecisionTreeClassifier_Visualization\", dpi=700, bbox_inches='tight')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(42,42))\nax.set_title(\"Visual represenation of the first decision tree(out of 100 trees) in the random forest\")\ntree.plot_tree(rf_model.estimators_[0], feature_names = feature_names, class_names = class_names, filled = True)\nplt.savefig('RandomForestClassifier_Visualization', dpi=700, bbox_inches='tight')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(42,42))\nax.set_title(\"Visual represenation of the XGBClassifier\")\nplot_tree(xgb_model, num_trees = 1)\nplt.savefig('XGBClassifier_Visualization', dpi=700, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wand.image import Image\nprint(\"Decision-making success rates of each classifier(%)\")\n\ncol_names = [\"Classifier Name\", \"Accuracy\", \"Precision score\", \"Recall score\", \"F1 Score\"]\n\n#Displaying the table\nprint(tabulate(tabulation_data, headers=col_names, tablefmt=\"outline\"))\n\n#Creating a dataframe\nop = pd.DataFrame(tabulation_data, columns=col_names, index=model_names)\n\n#Plotting the dataframe\nax = op.plot(figsize=(18, 8), title='Bar plot of performance metrics of the three models', kind='bar')\nfor container in ax.containers:\n    ax.bar_label(container)\nax.tick_params(colors='darkblue')\nplt.savefig(\"tabulations_graph\", facecolor = \"white\", transparent=False, bbox_inches='tight')\n\n#Converting dataframe to pdf\n\nfig, ax =plt.subplots(figsize=(12,4))\nax.axis('tight')\nax.axis('off')\nplt.title(\"Performance metrics of the three models\" ,y=1.0)\nrow_col_headers = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (2, 0), (3, 0)]\nthe_table = ax.table(cellText=op.values, colLabels=op.columns, loc='center')\nrow_col_cells = [the_table.get_celld()[row_col_header] for row_col_header in row_col_headers]\nfor cell in row_col_cells:\n    cell.set(facecolor = 'dimgray')\n    cell.get_text().set_color('white')\n    cell.get_text().set_fontweight('heavy')\n    \npdf = PdfPages(\"tabulation.pdf\")\npdf.savefig(fig, bbox_inches='tight')\npdf.close()\n\n#Converting pdf to png\npdf_filename = \"tabulation.pdf\"\nwith(Image(filename=pdf_filename, resolution=120)) as source: \n    for image in source.sequence:\n        Image(image).save(filename=\"tabulation.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_merged_columns = list(df_merged.columns)\nremove_indices = [df_merged_columns.index(i) + 1 for i in drop_columns]\nremove_indices.append(0)\nremove_indices.append(19)\nremove_indices.sort()\ncnt = 0\nprint(\"\\n\\n\\n\\n\")\nip = input(\"Enter the data :\")\nsplitter = chr(9)\nip_list = ip.split(splitter)\npatient_case_num = ip_list[0]\npatient_name = ip_list[1]\nfor ind in remove_indices:\n    del ip_list[ind-cnt]\n    cnt += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ip_ndarray = np.array(ip_list, dtype='float')\nprediction = best_model[\"model\"].predict([ip_ndarray])\nresult = \"extract\" if prediction[0]==1 else \"not extract\"\nprint(\"\\n\\n\\n\\n\\n\\n************************************\")\nips = ip[1:-1].split(\", \")[:2]\nprint(\"Patient \"+patient_name+\" bearing case no. \"+patient_case_num+\":\")\nprint(\"Decision is to\", result)\nprint(\"************************************\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}